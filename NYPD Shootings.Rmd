---
title: "NPYD Shootings"
date: "2022-10-06"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
## Get currrent data
url_in <- "https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"
```

# NYPD Shootings

## Importing in the Data

Now we can read in the data and look at it:

```{r import_data, echo=TRUE}
crime_data <- read_csv(url_in)
```

## Tidying the Data

```{r tidying_data, echo=TRUE}
crime_data <- crime_data %>% 
  select(-c(INCIDENT_KEY, PRECINCT, JURISDICTION_CODE, LOCATION_DESC, 
            X_COORD_CD, Y_COORD_CD, Latitude, Longitude, Lon_Lat))

crime <- crime_data %>% 
  rename(date = 'OCCUR_DATE', 
         time = 'OCCUR_TIME', 
         borough = 'BORO', 
         murder = 'STATISTICAL_MURDER_FLAG', 
         perp_age = 'PERP_AGE_GROUP', 
         perp_sex = 'PERP_SEX', 
         perp_race = 'PERP_RACE', 
         vic_age = 'VIC_AGE_GROUP', 
         vic_sex = 'VIC_SEX', 
         vic_race = 'VIC_RACE') %>% 
  mutate(date = mdy(date), 
         time = hms(time), 
         year = year(date), 
         month = month(date), 
         day = day(date), 
         hour = hour(time), 
         minute = minute(time), 
         perp_age = as.factor(perp_age), 
         perp_race = as.factor(perp_race),
         perp_sex = as.factor(perp_sex), 
         vic_age = as.factor(vic_age),
         vic_race = as.factor(vic_race), 
         vic_sex = as.factor(vic_sex)
         ) %>% 
  filter(date >= ymd('2020-01-01')) %>% 
  na.omit()

```

Taking a look at the data and a summary:

```{r tidying_data_2, echo=TRUE}

crime

summary(crime)

```

## Visualizing Data

In order to preserve the bulk of the observations, I have opted to leave the characteristics that lacked sufficient data alone. Only a few observations required the dplyr function na.omit() since they were missing adequate variables. 

We may observe an age breakdown for each of the five boroughs from 2020-2022 by factoring the number of gunshots by the victim's age. It is evident that the vast majority of gunshot victims in New York City are 25-44. 

```{r visualizing_data, echo=TRUE}

ggplot(crime) + 
  geom_bar(aes(x = borough, fill = borough)) + 
  facet_wrap(~vic_age) + 
  theme(legend.position = "top", 
        axis.text.x = element_text(angle = 90)) + 
  labs(title = "Shootings in New York City by Age From 2020-2022", y = NULL)

```

In a similar vein, we may segment the shootings by borough for the racial characteristics of the victims, showing that the victims are likewise predominantly black: 

```{r visualizing_data 2, echo=TRUE}

ggplot(crime) + 
  geom_bar(aes(x = borough, fill = borough)) + 
  facet_wrap(~vic_race) + 
  theme(legend.position = "top", 
        axis.text.x = element_text(angle = 90)) + 
  labs(title = "Shootings in New York City by Race From 2020-2022", y = NULL)

```

Finally, using data from a section of the dataset to train a linear regression model, I will use the model to determine if a homicide victim was killed based on the victim's ethnicity, sex, age, and the borough where the incident took place: 

```{r modeling_data, echo = TRUE}

train <- crime[1:410, ]
test <- crime[411:488, ]

model <- glm(murder ~ vic_age + vic_race + vic_sex + borough, data = train, 
             family = "binomial")
model

test$predict <- predict(model, test, type = "response")
test <- test %>% mutate(
  murder_binary = as.numeric(murder)
    )
cor.test(test$murder_binary, test$predict)

```

About five-percent of the time, the model seems to have a respectable accuracy rate for forecasting the outcome. The model would never be accurate enough to forecast a victim dying even once, therefore the model would theoretically be more accurate if it just assumed that the victim lives every time. 

## Conclusion

Both of the representations appear to show that Staten Island is by far the least risky borough for gun violence, while Brooklyn is by far the most hazardous. Violence per capita statistics may have different findings since this simply considers the total number of recorded instances and ignores population density. 

The reporting and recording of the data may have been biased. "Shooting" can be variously defined based on the individual precincts. For example, a gun being drawn at the victim could constitute a shooting in one precinct, but not in the other. The fact that not all shootings will be publicized is another instance of prejudice. Another example of bias data is victims of fatal gunshot wounds; victims of fatal gunshots will be reported at a higher rate than victims of non-lethal shootings.

The skewed reported statistics would probably exceed the actual population parameter for the gunshot fatality rate if the rate of shooting deaths were analyzed. I would argue that there is very little personal bias because the data set was picked for me, thus I have no personal relationship to it. Having said that, my method of tidying and cleaning the data was biased. I opted to leave out several characteristics because there was so much missing information, even though I could have retained them and left out the observations that lacked data. As a result, the characteristics of the shooters' perpetrators were substantially obscured, which forced my study to concentrate more on the shooting victims.